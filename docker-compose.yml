services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    restart: unless-stopped
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    depends_on:
    - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    volumes:
    - kafka-data:/var/lib/kafka/data
    restart: unless-stopped
  redis:
    image: redis:7
    container_name: redis
    command:
    - redis-server
    - --appendonly
    - 'yes'
    volumes:
    - redis-data:/data
    restart: unless-stopped
  kafka-init:
    build:
      context: ./kafka-components/kafka-init
      dockerfile: Dockerfile
    container_name: kafka-init
    depends_on:
    - kafka
    environment:
      KAFKA_BROKER: kafka:9092
    restart: 'no'
  kafka-connect:
    build:
      context: ./kafka-components/kafka-connect
      dockerfile: Dockerfile
    container_name: kafka-connect
    depends_on:
    - kafka
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: connect-cluster-1
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: 'false'
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
    ports:
    - 8083:8083
    restart: unless-stopped
  connect-init:
    build:
      context: ./kafka-components/kafka-connect/connect-init
      dockerfile: Dockerfile
    container_name: connect-init
    depends_on:
    - kafka-connect
    - postgres
    - kafka-init
    environment:
      CONNECT_URL: http://kafka-connect:8083
      KAFKA_BROKER: kafka:9092
      PG_HOST: postgres
      PG_PORT: '5432'
      PG_DB: smart_shelf
      PG_USER: bdt_user
      PG_PASS: bdt_password
    restart: 'no'
  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      POSTGRES_USER: bdt_user
      POSTGRES_PASSWORD: bdt_password
      POSTGRES_DB: smart_shelf
    ports:
    - 5432:5432
    volumes:
    - postgres-data:/var/lib/postgresql/data
    - ./postgresql:/docker-entrypoint-initdb.d:ro
    - ./data/db_csv:/import/csv:ro
    restart: unless-stopped
  kafka-producer-foot-traffic:
    build:
      context: ./kafka-components/kafka-producer-foot_traffic
      dockerfile: Dockerfile
    container_name: kafka-producer-foot-traffic
    depends_on:
    - kafka
    - redis
    environment:
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: '6379'
      REDIS_DB: '0'
      REDIS_STREAM: foot_traffic
      SLEEP: '0.125'
      TIME_SCALE: '4.0'
    restart: unless-stopped
  kafka-producer-pos:
    build:
      context: ./kafka-components/kafka-producer-pos
      dockerfile: Dockerfile
    container_name: kafka-producer-pos
    depends_on:
    - kafka
    - redis
    environment:
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: '6379'
      REDIS_DB: '0'
      REDIS_STREAM: pos_transactions
      SLEEP: '0.25'
      TIME_SCALE: '4.0'
    volumes:
    - ./data:/data:ro
    restart: unless-stopped
  kafka-producer-shelf:
    build:
      context: ./kafka-components/kafka-producer-shelf
      dockerfile: Dockerfile
    container_name: kafka-producer-shelf
    depends_on:
    - kafka
    - redis
    environment:
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: '6379'
      REDIS_DB: '0'
      REDIS_STREAM: shelf_events
      SHELF_SLEEP: '0.25'
    volumes:
    - ./data:/data:ro
    restart: unless-stopped
  kafka-producer-wh_shelf:
    build:
      context: ./kafka-components/kafka-producer-wh_shelf
      dockerfile: Dockerfile
    container_name: kafka-producer-wh_shelf
    depends_on:
    - kafka
    - redis
    environment:
      KAFKA_BROKER: kafka:9092
      REDIS_HOST: redis
      REDIS_PORT: '6379'
      REDIS_DB: '0'
      REDIS_STREAM: wh_events
    volumes:
    - ./data:/data:ro
    restart: unless-stopped
  spark-init-delta:
    build:
      context: ./spark-apps/deltalake
      dockerfile: Dockerfile
    container_name: spark-init-delta
    environment:
      DELTA_ROOT: /delta
      SPARK_WAREHOUSE_DIR: /tmp/spark-warehouse
      PYSPARK_SUBMIT_ARGS: '--packages io.delta:delta-spark_2.12:3.2.0 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
        --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
        pyspark-shell

        '
    volumes:
    - ./delta:/delta
    - ./spark-apps/deltalake/init_delta.py:/app/init_delta.py:ro
    command:
    - python
    - -u
    - /app/init_delta.py
    restart: 'no'
  spark-shelf-aggregator:
    build:
      context: ./spark-apps/shelf-aggregator
      dockerfile: Dockerfile
    container_name: spark-shelf-aggregator
    depends_on:
    - kafka
    environment:
      KAFKA_BROKER: kafka:9092
      TOPIC_SHELF_EVENTS: shelf_events
      TOPIC_SHELF_PROFILES: shelf_profiles
      TOPIC_SHELF_STATE: shelf_state
      JDBC_PG_URL: jdbc:postgresql://postgres:5432/smart_shelf
      JDBC_PG_USER: bdt_user
      JDBC_PG_PASSWORD: bdt_password
      BOOTSTRAP_FROM_PG: '1'
      DELTA_ROOT: /delta
      STARTING_OFFSETS: earliest
      CHECKPOINT_ROOT: /delta/_checkpoints/shelf_aggregator
    volumes:
    - ./delta:/delta
    restart: unless-stopped
  batch-state-updater:
    build:
      context: ./spark-apps/batch-state-updater
    environment:
      KAFKA_BROKER: kafka:9092
      TOPIC_POS_TRANSACTIONS: pos_transactions
      TOPIC_BATCH_STATE: shelf_batch_state
      JDBC_PG_URL: jdbc:postgresql://postgres:5432/smart_shelf
      JDBC_PG_USER: bdt_user
      JDBC_PG_PASSWORD: bdt_password
      BOOTSTRAP_FROM_PG: '1'
      DELTA_ROOT: /delta
      CHECKPOINT_ROOT: /delta/_checkpoints/batch_state_updater
      STARTING_OFFSETS: earliest
    volumes:
    - ./delta:/delta
    depends_on:
    - kafka
    - postgres
volumes:
  kafka-data: null
  redis-data: null
  postgres-data: null
