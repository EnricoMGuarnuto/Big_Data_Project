services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data/pgdata
      - ./data:/data:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME} -h localhost || exit 1"]
      interval: 3s
      timeout: 5s
      retries: 20
  refill-manager:
    build:
      context: ./refill_manager
    depends_on:
      - postgres
      - kafka
    environment:
      - PG_HOST=postgres
      - PG_PORT=5432
      - PG_DB=retaildb
      - PG_USER=retail
      - PG_PASS=retailpass
      - KAFKA_BROKER=kafka:9092
      - TOPIC_SHELF=shelf_events
  db-sql-jobs:
    image: postgres:16-alpine
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
    volumes:
      - ./postgresql/sql:/sql:ro
      - ./data:/data:ro
    entrypoint: ["sh", "-c",
      "psql postgresql://$DB_USER:$DB_PASSWORD@postgres:5432/$DB_NAME -v ON_ERROR_STOP=1 -f /sql/make_db.sql &&
       psql postgresql://$DB_USER:$DB_PASSWORD@postgres:5432/$DB_NAME -v ON_ERROR_STOP=1 -f /sql/db_management.sql"]
    restart: 'no'

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - minio_data:/data

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.1
    platform: linux/amd64
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:6.2.1
    platform: linux/amd64
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000

  kafka-producer-foot-traffic:
    build:
      context: ./kafka-components/kafka-producer-foot_traffic
      dockerfile: Dockerfile
    environment:
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC=foot_traffic
      - SLEEP=0.3
      - TIME_SCALE=60
    depends_on:
      - kafka
    volumes:
      - ./data:/data

  kafka-producer-shelf:
    build:
      context: ./kafka-components/kafka-producer-shelf
      dockerfile: Dockerfile
    environment:
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC_FOOT=foot_traffic
      - KAFKA_TOPIC_SHELF=shelf_events
    depends_on:
      - kafka
      - redis
    volumes:
      - ./data:/data

  kafka-producer-pos:
    build:
      context: ./kafka-components/kafka-producer-pos
      dockerfile: Dockerfile
    environment:
      - KAFKA_BROKER=kafka:9092
      - FOOT_TOPIC=foot_traffic
      - POS_TOPIC=pos_transactions
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - kafka
      - redis
      - kafka-producer-foot-traffic
    volumes:
      - ./data:/data

  kafka-consumer-shelf:
    build:
      context: ./kafka-components/kafka-consumer-shelf
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BROKER=kafka:9092
      - TOPIC_SHELF=shelf_events
      - GROUP_ID=db-shelf-consumer
      - PG_HOST=postgres
      - PG_PORT=5432
      - PG_DB=retaildb
      - PG_USER=retail
      - PG_PASS=retailpass

  kafka-consumer-pos:
    build:
      context: ./kafka-components/kafka-consumer-pos
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BROKER=kafka:9092
      - POS_TOPIC=pos_transactions
      - GROUP_ID=db-pos-consumer
      - PG_HOST=postgres
      - PG_PORT=5432
      - PG_DB=retaildb
      - PG_USER=retail
      - PG_PASS=retailpass

  spark:
    build:
      context: ./spark-components
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - PG_HOST=postgres
      - PG_DB=retaildb
      - PG_USER=retail
      - PG_PASS=retailpass
    volumes:
      - ./spark-components:/app
      - ./spark-checkpoints:/chk
    depends_on:
      - kafka
      - postgres
    ports:
      - "4040:4040"
    command: >
      spark-submit
        --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.postgresql:postgresql:42.7.3
        --conf spark.sql.shuffle.partitions=2
        /app/streaming_supervisor.py

volumes:
  minio_data:
  postgres_data:
  redis_data: